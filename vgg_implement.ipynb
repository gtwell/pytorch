{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from logger import Logger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_transforms = transforms.Compose([\n",
    "    transforms.RandomSizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "data_dir = './data'\n",
    "batch_size = 16\n",
    "learning_rate = 0.001\n",
    "total_step = 20000\n",
    "image_datasets = datasets.ImageFolder(data_dir, data_transforms)\n",
    "dataloader = torch.utils.data.DataLoader(image_datasets, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "class_names = image_datasets.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VGG_16(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG_16, self).__init__()\n",
    "        self.layers1 = nn.Sequential(nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "                                     nn.BatchNorm2d(64),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "                                     nn.BatchNorm2d(64),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.MaxPool2d(2))\n",
    "        \n",
    "        self.layers2 = nn.Sequential(nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "                                     nn.BatchNorm2d(128),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "                                     nn.BatchNorm2d(128),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.MaxPool2d(2))\n",
    "        \n",
    "        self.layers3 = nn.Sequential(nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "                                     nn.BatchNorm2d(256),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "                                     nn.BatchNorm2d(256),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.MaxPool2d(2))\n",
    "        \n",
    "        self.layers4 = nn.Sequential(nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "                                     nn.BatchNorm2d(512),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "                                     nn.BatchNorm2d(512),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "                                     nn.BatchNorm2d(512),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.MaxPool2d(2))\n",
    "        \n",
    "        self.layers5 = nn.Sequential(nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "                                     nn.BatchNorm2d(512),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "                                     nn.BatchNorm2d(512),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "                                     nn.BatchNorm2d(512),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.MaxPool2d(2))\n",
    "        \n",
    "        self.fc1 = nn.Linear(7*7*512, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 1024)\n",
    "        self.fc3 = nn.Linear(1024, 2)\n",
    "    def forward(self, x):\n",
    "        out = self.layers1(x)\n",
    "        out = self.layers2(out)\n",
    "        out = self.layers3(out)\n",
    "        out = self.layers4(out)\n",
    "        out = self.layers5(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG_16 (\n",
       "  (layers1): Sequential (\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (2): ReLU ()\n",
       "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (5): ReLU ()\n",
       "    (6): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "  )\n",
       "  (layers2): Sequential (\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (2): ReLU ()\n",
       "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (5): ReLU ()\n",
       "    (6): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "  )\n",
       "  (layers3): Sequential (\n",
       "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (2): ReLU ()\n",
       "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (5): ReLU ()\n",
       "    (6): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "  )\n",
       "  (layers4): Sequential (\n",
       "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (2): ReLU ()\n",
       "    (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (5): ReLU ()\n",
       "    (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (8): ReLU ()\n",
       "    (9): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "  )\n",
       "  (layers5): Sequential (\n",
       "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (2): ReLU ()\n",
       "    (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (5): ReLU ()\n",
       "    (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (8): ReLU ()\n",
       "    (9): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "  )\n",
       "  (fc1): Linear (25088 -> 1024)\n",
       "  (fc2): Linear (1024 -> 1024)\n",
       "  (fc3): Linear (1024 -> 2)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn = VGG_16()\n",
    "cnn.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=learning_rate)\n",
    "logger = Logger('./logs_vgg_bn')\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "iter_per_epoch = len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [100/20000], Loss: 0.8800, Acc: 0.8750\n",
      "Step [200/20000], Loss: 0.6777, Acc: 0.5625\n",
      "Step [300/20000], Loss: 0.6200, Acc: 0.5625\n",
      "Step [400/20000], Loss: 0.7457, Acc: 0.4375\n",
      "Step [500/20000], Loss: 0.9846, Acc: 0.5000\n",
      "Step [600/20000], Loss: 0.8107, Acc: 0.3750\n",
      "Step [700/20000], Loss: 0.8996, Acc: 0.5000\n",
      "Step [800/20000], Loss: 0.5526, Acc: 0.8125\n",
      "Step [900/20000], Loss: 0.6066, Acc: 0.6250\n",
      "Step [1000/20000], Loss: 0.7383, Acc: 0.6875\n",
      "Step [1100/20000], Loss: 0.6460, Acc: 0.6250\n",
      "Step [1200/20000], Loss: 0.5830, Acc: 0.6250\n",
      "Step [1300/20000], Loss: 0.7629, Acc: 0.4375\n",
      "Step [1400/20000], Loss: 0.8527, Acc: 0.7500\n",
      "Step [1500/20000], Loss: 0.6066, Acc: 0.6875\n",
      "Step [1600/20000], Loss: 0.7787, Acc: 0.4375\n",
      "Step [1700/20000], Loss: 0.6014, Acc: 0.7500\n",
      "Step [1800/20000], Loss: 0.6350, Acc: 0.7500\n",
      "Step [1900/20000], Loss: 0.5995, Acc: 0.6250\n",
      "Step [2000/20000], Loss: 0.6391, Acc: 0.7500\n",
      "Step [2100/20000], Loss: 0.6021, Acc: 0.6250\n",
      "Step [2200/20000], Loss: 0.5877, Acc: 0.7500\n",
      "Step [2300/20000], Loss: 0.5974, Acc: 0.6875\n",
      "Step [2400/20000], Loss: 0.5597, Acc: 0.6875\n",
      "Step [2500/20000], Loss: 1.0245, Acc: 0.3750\n",
      "Step [2600/20000], Loss: 0.7450, Acc: 0.5000\n",
      "Step [2700/20000], Loss: 0.6548, Acc: 0.6875\n",
      "Step [2800/20000], Loss: 0.4353, Acc: 0.8125\n",
      "Step [2900/20000], Loss: 0.5823, Acc: 0.7500\n",
      "Step [3000/20000], Loss: 0.3892, Acc: 0.9375\n",
      "Step [3100/20000], Loss: 0.6658, Acc: 0.6250\n",
      "Step [3200/20000], Loss: 0.5032, Acc: 0.6875\n",
      "Step [3300/20000], Loss: 0.5047, Acc: 0.8750\n",
      "Step [3400/20000], Loss: 0.4774, Acc: 0.7500\n",
      "Step [3500/20000], Loss: 0.6243, Acc: 0.5625\n",
      "Step [3600/20000], Loss: 0.4108, Acc: 0.9375\n",
      "Step [3700/20000], Loss: 0.8387, Acc: 0.6250\n",
      "Step [3800/20000], Loss: 0.9199, Acc: 0.5000\n",
      "Step [3900/20000], Loss: 0.6361, Acc: 0.6250\n",
      "Step [4000/20000], Loss: 0.4925, Acc: 0.8125\n",
      "Step [4100/20000], Loss: 0.3385, Acc: 0.9375\n",
      "Step [4200/20000], Loss: 0.5720, Acc: 0.6875\n",
      "Step [4300/20000], Loss: 0.5208, Acc: 0.6875\n",
      "Step [4400/20000], Loss: 0.4750, Acc: 0.6875\n",
      "Step [4500/20000], Loss: 0.3105, Acc: 0.9375\n",
      "Step [4600/20000], Loss: 0.3546, Acc: 0.8125\n",
      "Step [4700/20000], Loss: 0.7920, Acc: 0.6250\n",
      "Step [4800/20000], Loss: 0.4541, Acc: 0.8125\n",
      "Step [4900/20000], Loss: 0.5541, Acc: 0.6875\n",
      "Step [5000/20000], Loss: 0.3498, Acc: 0.8750\n",
      "Step [5100/20000], Loss: 0.7898, Acc: 0.6250\n",
      "Step [5200/20000], Loss: 0.3218, Acc: 0.8125\n",
      "Step [5300/20000], Loss: 0.3413, Acc: 0.8125\n",
      "Step [5400/20000], Loss: 0.6988, Acc: 0.6250\n",
      "Step [5500/20000], Loss: 0.5966, Acc: 0.6250\n",
      "Step [5600/20000], Loss: 0.4766, Acc: 0.7500\n",
      "Step [5700/20000], Loss: 1.0343, Acc: 0.6250\n",
      "Step [5800/20000], Loss: 0.2700, Acc: 0.8750\n",
      "Step [5900/20000], Loss: 0.5036, Acc: 0.6875\n",
      "Step [6000/20000], Loss: 0.4202, Acc: 0.8125\n",
      "Step [6100/20000], Loss: 0.4763, Acc: 0.8125\n",
      "Step [6200/20000], Loss: 0.3690, Acc: 0.8125\n",
      "Step [6300/20000], Loss: 0.3679, Acc: 0.9375\n",
      "Step [6400/20000], Loss: 0.5768, Acc: 0.6250\n",
      "Step [6500/20000], Loss: 0.1846, Acc: 1.0000\n",
      "Step [6600/20000], Loss: 0.4233, Acc: 0.7500\n",
      "Step [6700/20000], Loss: 0.4194, Acc: 0.7500\n",
      "Step [6800/20000], Loss: 0.2004, Acc: 0.9375\n",
      "Step [6900/20000], Loss: 0.2026, Acc: 1.0000\n",
      "Step [7000/20000], Loss: 0.3409, Acc: 0.8750\n",
      "Step [7100/20000], Loss: 0.2086, Acc: 0.8750\n",
      "Step [7200/20000], Loss: 0.4316, Acc: 0.7500\n",
      "Step [7300/20000], Loss: 0.2490, Acc: 0.9375\n",
      "Step [7400/20000], Loss: 0.2226, Acc: 0.9375\n",
      "Step [7500/20000], Loss: 0.2652, Acc: 0.9375\n",
      "Step [7600/20000], Loss: 0.3329, Acc: 0.8750\n",
      "Step [7700/20000], Loss: 0.3976, Acc: 0.8750\n",
      "Step [7800/20000], Loss: 0.1848, Acc: 0.9375\n",
      "Step [7900/20000], Loss: 0.5334, Acc: 0.8125\n",
      "Step [8000/20000], Loss: 0.4585, Acc: 0.8750\n",
      "Step [8100/20000], Loss: 0.2397, Acc: 0.9375\n",
      "Step [8200/20000], Loss: 0.1834, Acc: 0.9375\n",
      "Step [8300/20000], Loss: 0.1709, Acc: 0.8750\n",
      "Step [8400/20000], Loss: 0.2648, Acc: 0.9375\n",
      "Step [8500/20000], Loss: 0.5055, Acc: 0.7500\n",
      "Step [8600/20000], Loss: 0.2459, Acc: 0.9375\n",
      "Step [8700/20000], Loss: 0.4296, Acc: 0.8125\n",
      "Step [8800/20000], Loss: 0.5139, Acc: 0.8750\n",
      "Step [8900/20000], Loss: 0.2206, Acc: 0.9375\n",
      "Step [9000/20000], Loss: 0.6302, Acc: 0.6875\n",
      "Step [9100/20000], Loss: 0.4173, Acc: 0.8125\n",
      "Step [9200/20000], Loss: 0.3442, Acc: 0.8125\n",
      "Step [9300/20000], Loss: 0.3245, Acc: 0.8750\n",
      "Step [9400/20000], Loss: 0.3431, Acc: 0.8750\n",
      "Step [9500/20000], Loss: 0.3117, Acc: 0.8125\n",
      "Step [9600/20000], Loss: 0.2837, Acc: 0.9375\n",
      "Step [9700/20000], Loss: 0.5955, Acc: 0.6875\n",
      "Step [9800/20000], Loss: 0.5463, Acc: 0.6875\n",
      "Step [9900/20000], Loss: 0.1951, Acc: 1.0000\n",
      "Step [10000/20000], Loss: 0.2663, Acc: 0.9375\n",
      "Step [10100/20000], Loss: 0.1755, Acc: 0.9375\n",
      "Step [10200/20000], Loss: 0.0921, Acc: 1.0000\n",
      "Step [10300/20000], Loss: 0.2672, Acc: 0.8750\n",
      "Step [10400/20000], Loss: 0.7200, Acc: 0.8750\n",
      "Step [10500/20000], Loss: 0.3971, Acc: 0.8125\n",
      "Step [10600/20000], Loss: 0.6093, Acc: 0.6250\n",
      "Step [10700/20000], Loss: 0.3419, Acc: 0.8750\n",
      "Step [10800/20000], Loss: 0.2721, Acc: 0.8750\n",
      "Step [10900/20000], Loss: 0.2940, Acc: 0.8750\n",
      "Step [11000/20000], Loss: 1.0351, Acc: 0.6250\n",
      "Step [11100/20000], Loss: 0.3169, Acc: 0.8125\n",
      "Step [11200/20000], Loss: 0.2037, Acc: 1.0000\n",
      "Step [11300/20000], Loss: 0.6458, Acc: 0.7500\n",
      "Step [11400/20000], Loss: 0.6079, Acc: 0.8125\n",
      "Step [11500/20000], Loss: 0.1579, Acc: 0.9375\n",
      "Step [11600/20000], Loss: 0.2220, Acc: 0.8750\n",
      "Step [11700/20000], Loss: 0.5480, Acc: 0.8750\n",
      "Step [11800/20000], Loss: 0.4622, Acc: 0.8125\n",
      "Step [11900/20000], Loss: 0.3395, Acc: 0.8750\n",
      "Step [12000/20000], Loss: 0.4518, Acc: 0.8125\n",
      "Step [12100/20000], Loss: 0.5875, Acc: 0.6250\n",
      "Step [12200/20000], Loss: 0.3476, Acc: 0.8125\n",
      "Step [12300/20000], Loss: 0.3625, Acc: 0.8125\n",
      "Step [12400/20000], Loss: 0.1769, Acc: 0.9375\n",
      "Step [12500/20000], Loss: 0.3243, Acc: 0.8125\n",
      "Step [12600/20000], Loss: 0.4658, Acc: 0.8125\n",
      "Step [12700/20000], Loss: 0.1045, Acc: 0.9375\n",
      "Step [12800/20000], Loss: 0.1685, Acc: 0.9375\n",
      "Step [12900/20000], Loss: 0.1684, Acc: 0.9375\n",
      "Step [13000/20000], Loss: 0.3074, Acc: 0.8750\n",
      "Step [13100/20000], Loss: 0.3020, Acc: 0.9375\n",
      "Step [13200/20000], Loss: 0.1589, Acc: 0.9375\n",
      "Step [13300/20000], Loss: 0.4084, Acc: 0.8125\n",
      "Step [13400/20000], Loss: 0.1504, Acc: 0.9375\n",
      "Step [13500/20000], Loss: 0.1385, Acc: 1.0000\n",
      "Step [13600/20000], Loss: 0.3821, Acc: 0.8750\n",
      "Step [13700/20000], Loss: 0.0962, Acc: 1.0000\n",
      "Step [13800/20000], Loss: 0.1661, Acc: 0.8750\n",
      "Step [13900/20000], Loss: 0.4301, Acc: 0.8750\n",
      "Step [14000/20000], Loss: 0.1854, Acc: 0.8750\n",
      "Step [14100/20000], Loss: 0.2938, Acc: 0.8750\n",
      "Step [14200/20000], Loss: 0.3242, Acc: 0.8750\n",
      "Step [14300/20000], Loss: 0.1128, Acc: 1.0000\n",
      "Step [14400/20000], Loss: 0.2306, Acc: 0.8750\n",
      "Step [14500/20000], Loss: 0.9923, Acc: 0.5625\n",
      "Step [14600/20000], Loss: 0.5771, Acc: 0.7500\n",
      "Step [14700/20000], Loss: 0.1137, Acc: 1.0000\n",
      "Step [14800/20000], Loss: 0.3289, Acc: 0.8125\n",
      "Step [14900/20000], Loss: 0.3580, Acc: 0.8750\n",
      "Step [15000/20000], Loss: 0.1759, Acc: 0.9375\n",
      "Step [15100/20000], Loss: 0.2329, Acc: 0.8750\n",
      "Step [15200/20000], Loss: 0.2780, Acc: 0.8750\n",
      "Step [15300/20000], Loss: 0.1483, Acc: 0.8750\n",
      "Step [15400/20000], Loss: 0.2141, Acc: 0.9375\n",
      "Step [15500/20000], Loss: 0.0979, Acc: 1.0000\n",
      "Step [15600/20000], Loss: 0.3481, Acc: 0.8750\n",
      "Step [15700/20000], Loss: 0.1733, Acc: 0.8750\n",
      "Step [15800/20000], Loss: 0.3453, Acc: 0.8750\n",
      "Step [15900/20000], Loss: 0.0766, Acc: 1.0000\n",
      "Step [16000/20000], Loss: 0.2605, Acc: 0.8750\n",
      "Step [16100/20000], Loss: 0.2080, Acc: 0.8750\n",
      "Step [16200/20000], Loss: 0.3052, Acc: 0.9375\n",
      "Step [16300/20000], Loss: 0.1619, Acc: 1.0000\n",
      "Step [16400/20000], Loss: 0.3206, Acc: 0.8750\n",
      "Step [16500/20000], Loss: 0.7949, Acc: 0.5625\n",
      "Step [16600/20000], Loss: 0.4010, Acc: 0.8750\n",
      "Step [16700/20000], Loss: 0.1426, Acc: 0.9375\n",
      "Step [16800/20000], Loss: 0.2448, Acc: 0.9375\n",
      "Step [16900/20000], Loss: 0.6805, Acc: 0.6875\n",
      "Step [17000/20000], Loss: 0.4019, Acc: 0.7500\n",
      "Step [17100/20000], Loss: 0.3253, Acc: 0.8750\n",
      "Step [17200/20000], Loss: 0.9629, Acc: 0.6250\n",
      "Step [17300/20000], Loss: 0.2342, Acc: 0.8750\n",
      "Step [17400/20000], Loss: 0.3355, Acc: 0.8125\n",
      "Step [17500/20000], Loss: 0.3044, Acc: 0.8125\n",
      "Step [17600/20000], Loss: 0.3169, Acc: 0.9375\n",
      "Step [17700/20000], Loss: 0.2302, Acc: 0.8750\n",
      "Step [17800/20000], Loss: 0.1924, Acc: 0.9375\n",
      "Step [17900/20000], Loss: 0.2232, Acc: 0.8750\n",
      "Step [18000/20000], Loss: 0.4534, Acc: 0.8125\n",
      "Step [18100/20000], Loss: 0.2667, Acc: 0.8750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [18200/20000], Loss: 0.1904, Acc: 0.9375\n",
      "Step [18300/20000], Loss: 0.2392, Acc: 0.8750\n",
      "Step [18400/20000], Loss: 0.3504, Acc: 0.8750\n",
      "Step [18500/20000], Loss: 0.2008, Acc: 1.0000\n",
      "Step [18600/20000], Loss: 0.4306, Acc: 0.8125\n",
      "Step [18700/20000], Loss: 0.2697, Acc: 0.8750\n",
      "Step [18800/20000], Loss: 0.1381, Acc: 0.9375\n",
      "Step [18900/20000], Loss: 0.4499, Acc: 0.8125\n",
      "Step [19000/20000], Loss: 0.2715, Acc: 0.8125\n",
      "Step [19100/20000], Loss: 0.2789, Acc: 0.8125\n",
      "Step [19200/20000], Loss: 0.1786, Acc: 0.9375\n",
      "Step [19300/20000], Loss: 0.1474, Acc: 1.0000\n",
      "Step [19400/20000], Loss: 0.3025, Acc: 0.8125\n",
      "Step [19500/20000], Loss: 0.3004, Acc: 0.8750\n",
      "Step [19600/20000], Loss: 0.5279, Acc: 0.6875\n",
      "Step [19700/20000], Loss: 0.3224, Acc: 0.9375\n",
      "Step [19800/20000], Loss: 0.1828, Acc: 0.9375\n",
      "Step [19900/20000], Loss: 0.4606, Acc: 0.7500\n",
      "Step [20000/20000], Loss: 0.2107, Acc: 0.9375\n"
     ]
    }
   ],
   "source": [
    "for step in range(total_step):\n",
    "    if (step+1)%iter_per_epoch:\n",
    "        data_iter = iter(dataloader)\n",
    "    images, labels = next(data_iter)\n",
    "    images, labels = Variable(images).cuda(), Variable(labels).cuda()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = cnn(images)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    _, argmax = torch.max(outputs, 1)\n",
    "    accuracy = (labels == argmax.squeeze()).float().mean()\n",
    "    if (step+1) % 100 == 0:\n",
    "        print ('Step [%d/%d], Loss: %.4f, Acc: %.4f' \n",
    "               %(step+1, total_step, loss.data[0], accuracy.data[0]))\n",
    "\n",
    "        #============ TensorBoard logging ============#\n",
    "        # (1) Log the scalar values\n",
    "        info = {\n",
    "            'loss': loss.data[0],\n",
    "            'accuracy': accuracy.data[0]\n",
    "        }\n",
    "\n",
    "        for tag, value in info.items():\n",
    "            logger.scalar_summary(tag, value, step+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the train images: 87 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in dataloader:\n",
    "    images = Variable(images.cuda())\n",
    "#     net.eval()\n",
    "    outputs = cnn(images)\n",
    "#     print(outputs.data)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "#     print(predicted)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted.cpu() == labels).sum()\n",
    "    \n",
    "print('Accuracy of the network on the train images: %d %%' % (100*correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(cnn.state_dict(),'model_vgg_bn.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.00001\n",
    "total_step = 10000\n",
    "net = VGG_16()\n",
    "net.cuda()\n",
    "net.load_state_dict(torch.load('model_vgg_bn.pkl'))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "logger = Logger('./logs_vgg_bn2')\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "iter_per_epoch = len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [100/10000], Loss: 0.3241, Acc: 0.8125\n",
      "Step [200/10000], Loss: 0.2328, Acc: 0.9375\n",
      "Step [300/10000], Loss: 0.1594, Acc: 0.9375\n",
      "Step [400/10000], Loss: 0.1974, Acc: 0.8750\n",
      "Step [500/10000], Loss: 0.4362, Acc: 0.6875\n",
      "Step [600/10000], Loss: 0.1052, Acc: 1.0000\n",
      "Step [700/10000], Loss: 0.4611, Acc: 0.6875\n",
      "Step [800/10000], Loss: 0.2384, Acc: 0.8750\n",
      "Step [900/10000], Loss: 0.4951, Acc: 0.6875\n",
      "Step [1000/10000], Loss: 0.3143, Acc: 0.7500\n",
      "Step [1100/10000], Loss: 0.1014, Acc: 1.0000\n",
      "Step [1200/10000], Loss: 0.3505, Acc: 0.9375\n",
      "Step [1300/10000], Loss: 0.2088, Acc: 0.9375\n",
      "Step [1400/10000], Loss: 0.4597, Acc: 0.7500\n",
      "Step [1500/10000], Loss: 0.1962, Acc: 0.9375\n",
      "Step [1600/10000], Loss: 0.1881, Acc: 0.9375\n",
      "Step [1700/10000], Loss: 0.0845, Acc: 1.0000\n",
      "Step [1800/10000], Loss: 0.3110, Acc: 0.9375\n",
      "Step [1900/10000], Loss: 0.2963, Acc: 0.7500\n",
      "Step [2000/10000], Loss: 0.4167, Acc: 0.8750\n",
      "Step [2100/10000], Loss: 0.1105, Acc: 1.0000\n",
      "Step [2200/10000], Loss: 0.1877, Acc: 0.9375\n",
      "Step [2300/10000], Loss: 0.1810, Acc: 0.9375\n",
      "Step [2400/10000], Loss: 0.1656, Acc: 0.9375\n",
      "Step [2500/10000], Loss: 0.1485, Acc: 1.0000\n",
      "Step [2600/10000], Loss: 0.1282, Acc: 1.0000\n",
      "Step [2700/10000], Loss: 0.4679, Acc: 0.7500\n",
      "Step [2800/10000], Loss: 0.1699, Acc: 0.9375\n",
      "Step [2900/10000], Loss: 0.0789, Acc: 1.0000\n",
      "Step [3000/10000], Loss: 0.2248, Acc: 0.8125\n",
      "Step [3100/10000], Loss: 0.4543, Acc: 0.9375\n",
      "Step [3200/10000], Loss: 0.1956, Acc: 0.8750\n",
      "Step [3300/10000], Loss: 0.1226, Acc: 0.9375\n",
      "Step [3400/10000], Loss: 0.0998, Acc: 0.9375\n",
      "Step [3500/10000], Loss: 0.1052, Acc: 1.0000\n",
      "Step [3600/10000], Loss: 0.3324, Acc: 0.9375\n",
      "Step [3700/10000], Loss: 0.2401, Acc: 0.9375\n",
      "Step [3800/10000], Loss: 0.1464, Acc: 0.8750\n",
      "Step [3900/10000], Loss: 0.2083, Acc: 0.9375\n",
      "Step [4000/10000], Loss: 0.1526, Acc: 0.9375\n",
      "Step [4100/10000], Loss: 0.3439, Acc: 0.8750\n",
      "Step [4200/10000], Loss: 0.2832, Acc: 0.8750\n",
      "Step [4300/10000], Loss: 0.3252, Acc: 0.8125\n",
      "Step [4400/10000], Loss: 0.2615, Acc: 0.8750\n",
      "Step [4500/10000], Loss: 0.3487, Acc: 0.8750\n",
      "Step [4600/10000], Loss: 0.3962, Acc: 0.8125\n",
      "Step [4700/10000], Loss: 0.5284, Acc: 0.8125\n",
      "Step [4800/10000], Loss: 0.1493, Acc: 0.9375\n",
      "Step [4900/10000], Loss: 0.0885, Acc: 0.9375\n",
      "Step [5000/10000], Loss: 0.6868, Acc: 0.6250\n",
      "Step [5100/10000], Loss: 0.1755, Acc: 0.8750\n",
      "Step [5200/10000], Loss: 0.0497, Acc: 1.0000\n",
      "Step [5300/10000], Loss: 0.1958, Acc: 0.9375\n",
      "Step [5400/10000], Loss: 0.1636, Acc: 0.9375\n",
      "Step [5500/10000], Loss: 0.3378, Acc: 0.8750\n",
      "Step [5600/10000], Loss: 0.1170, Acc: 1.0000\n",
      "Step [5700/10000], Loss: 0.1831, Acc: 0.9375\n",
      "Step [5800/10000], Loss: 0.1420, Acc: 0.9375\n",
      "Step [5900/10000], Loss: 0.3849, Acc: 0.6875\n",
      "Step [6000/10000], Loss: 0.2566, Acc: 0.8125\n",
      "Step [6100/10000], Loss: 0.2654, Acc: 0.8125\n",
      "Step [6200/10000], Loss: 0.1998, Acc: 0.9375\n",
      "Step [6300/10000], Loss: 0.2873, Acc: 0.8125\n",
      "Step [6400/10000], Loss: 0.3815, Acc: 0.8750\n",
      "Step [6500/10000], Loss: 0.4989, Acc: 0.7500\n",
      "Step [6600/10000], Loss: 0.1189, Acc: 1.0000\n",
      "Step [6700/10000], Loss: 0.1224, Acc: 0.9375\n",
      "Step [6800/10000], Loss: 0.2095, Acc: 0.8750\n",
      "Step [6900/10000], Loss: 0.3827, Acc: 0.8750\n",
      "Step [7000/10000], Loss: 0.1519, Acc: 0.9375\n",
      "Step [7100/10000], Loss: 0.6809, Acc: 0.6875\n",
      "Step [7200/10000], Loss: 0.3507, Acc: 0.8750\n",
      "Step [7300/10000], Loss: 0.2169, Acc: 0.9375\n",
      "Step [7400/10000], Loss: 0.4044, Acc: 0.8750\n",
      "Step [7500/10000], Loss: 0.1203, Acc: 0.9375\n",
      "Step [7600/10000], Loss: 0.2717, Acc: 0.8750\n",
      "Step [7700/10000], Loss: 0.2666, Acc: 0.8750\n",
      "Step [7800/10000], Loss: 0.3385, Acc: 0.7500\n",
      "Step [7900/10000], Loss: 0.2933, Acc: 0.7500\n",
      "Step [8000/10000], Loss: 0.2822, Acc: 0.8750\n",
      "Step [8100/10000], Loss: 0.3871, Acc: 0.9375\n",
      "Step [8200/10000], Loss: 0.2247, Acc: 0.8750\n",
      "Step [8300/10000], Loss: 0.3443, Acc: 0.8125\n",
      "Step [8400/10000], Loss: 0.2090, Acc: 0.9375\n",
      "Step [8500/10000], Loss: 0.2257, Acc: 0.8750\n",
      "Step [8600/10000], Loss: 0.0742, Acc: 1.0000\n",
      "Step [8700/10000], Loss: 0.2811, Acc: 0.8750\n",
      "Step [8800/10000], Loss: 0.1898, Acc: 0.8750\n",
      "Step [8900/10000], Loss: 0.1791, Acc: 0.8125\n",
      "Step [9000/10000], Loss: 0.1256, Acc: 1.0000\n",
      "Step [9100/10000], Loss: 0.2490, Acc: 0.8750\n",
      "Step [9200/10000], Loss: 0.1395, Acc: 1.0000\n",
      "Step [9300/10000], Loss: 0.2651, Acc: 0.8750\n",
      "Step [9400/10000], Loss: 0.5352, Acc: 0.7500\n",
      "Step [9500/10000], Loss: 0.4107, Acc: 0.8125\n",
      "Step [9600/10000], Loss: 0.5987, Acc: 0.8125\n",
      "Step [9700/10000], Loss: 0.1819, Acc: 0.9375\n",
      "Step [9800/10000], Loss: 0.3475, Acc: 0.8125\n",
      "Step [9900/10000], Loss: 0.2765, Acc: 0.8750\n",
      "Step [10000/10000], Loss: 0.3406, Acc: 0.8750\n"
     ]
    }
   ],
   "source": [
    "for step in range(total_step):\n",
    "    if (step+1)%iter_per_epoch:\n",
    "        data_iter = iter(dataloader)\n",
    "    images, labels = next(data_iter)\n",
    "    images, labels = Variable(images).cuda(), Variable(labels).cuda()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = net(images)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    _, argmax = torch.max(outputs, 1)\n",
    "    accuracy = (labels == argmax.squeeze()).float().mean()\n",
    "    if (step+1) % 100 == 0:\n",
    "        print ('Step [%d/%d], Loss: %.4f, Acc: %.4f' \n",
    "               %(step+1, total_step, loss.data[0], accuracy.data[0]))\n",
    "\n",
    "        #============ TensorBoard logging ============#\n",
    "        # (1) Log the scalar values\n",
    "        info = {\n",
    "            'loss': loss.data[0],\n",
    "            'accuracy': accuracy.data[0]\n",
    "        }\n",
    "\n",
    "        for tag, value in info.items():\n",
    "            logger.scalar_summary(tag, value, step+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(),'model_vgg_bn2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.00001\n",
    "total_step = 10000\n",
    "net2 = VGG_16()\n",
    "net2.cuda()\n",
    "net2.load_state_dict(torch.load('model_vgg_bn2.pkl'))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "logger = Logger('./logs_vgg_bn3')\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "iter_per_epoch = len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [100/10000], Loss: 0.2127, Acc: 0.8750\n",
      "Step [200/10000], Loss: 0.2975, Acc: 0.9375\n",
      "Step [300/10000], Loss: 0.3010, Acc: 0.8750\n",
      "Step [400/10000], Loss: 0.4482, Acc: 0.7500\n",
      "Step [500/10000], Loss: 0.1947, Acc: 0.9375\n",
      "Step [600/10000], Loss: 0.0754, Acc: 1.0000\n",
      "Step [700/10000], Loss: 0.3919, Acc: 0.8125\n",
      "Step [800/10000], Loss: 0.2257, Acc: 0.9375\n",
      "Step [900/10000], Loss: 0.5379, Acc: 0.7500\n",
      "Step [1000/10000], Loss: 0.2906, Acc: 0.8125\n",
      "Step [1100/10000], Loss: 0.5314, Acc: 0.8125\n",
      "Step [1200/10000], Loss: 0.2847, Acc: 0.8125\n",
      "Step [1300/10000], Loss: 0.1318, Acc: 0.9375\n",
      "Step [1400/10000], Loss: 0.1903, Acc: 0.8750\n",
      "Step [1500/10000], Loss: 0.2306, Acc: 0.8750\n",
      "Step [1600/10000], Loss: 0.2831, Acc: 0.9375\n",
      "Step [1700/10000], Loss: 0.1910, Acc: 0.9375\n",
      "Step [1800/10000], Loss: 0.1961, Acc: 0.8750\n",
      "Step [1900/10000], Loss: 0.2632, Acc: 0.8750\n",
      "Step [2000/10000], Loss: 0.4905, Acc: 0.8125\n",
      "Step [2100/10000], Loss: 0.1666, Acc: 0.9375\n",
      "Step [2200/10000], Loss: 0.0645, Acc: 1.0000\n",
      "Step [2300/10000], Loss: 0.3730, Acc: 0.7500\n",
      "Step [2400/10000], Loss: 0.2491, Acc: 0.8125\n",
      "Step [2500/10000], Loss: 0.3145, Acc: 0.8125\n",
      "Step [2600/10000], Loss: 0.4542, Acc: 0.9375\n",
      "Step [2700/10000], Loss: 0.2902, Acc: 0.9375\n",
      "Step [2800/10000], Loss: 0.0246, Acc: 1.0000\n",
      "Step [2900/10000], Loss: 0.1461, Acc: 1.0000\n",
      "Step [3000/10000], Loss: 0.2273, Acc: 0.8750\n",
      "Step [3100/10000], Loss: 0.3391, Acc: 0.8125\n",
      "Step [3200/10000], Loss: 0.2199, Acc: 0.9375\n",
      "Step [3300/10000], Loss: 0.1670, Acc: 0.9375\n",
      "Step [3400/10000], Loss: 0.1592, Acc: 0.9375\n",
      "Step [3500/10000], Loss: 0.0849, Acc: 1.0000\n",
      "Step [3600/10000], Loss: 0.3504, Acc: 0.8750\n",
      "Step [3700/10000], Loss: 0.2739, Acc: 0.8750\n",
      "Step [3800/10000], Loss: 0.3647, Acc: 0.8125\n",
      "Step [3900/10000], Loss: 0.4158, Acc: 0.8125\n",
      "Step [4000/10000], Loss: 0.1352, Acc: 1.0000\n",
      "Step [4100/10000], Loss: 0.2702, Acc: 0.8125\n",
      "Step [4200/10000], Loss: 0.2191, Acc: 0.9375\n",
      "Step [4300/10000], Loss: 0.1451, Acc: 0.9375\n",
      "Step [4400/10000], Loss: 0.2253, Acc: 0.8750\n",
      "Step [4500/10000], Loss: 0.1910, Acc: 0.9375\n",
      "Step [4600/10000], Loss: 0.3192, Acc: 0.8750\n",
      "Step [4700/10000], Loss: 0.2267, Acc: 0.9375\n",
      "Step [4800/10000], Loss: 0.1556, Acc: 0.9375\n",
      "Step [4900/10000], Loss: 0.2653, Acc: 0.8750\n",
      "Step [5000/10000], Loss: 0.2169, Acc: 0.9375\n",
      "Step [5100/10000], Loss: 0.0595, Acc: 1.0000\n",
      "Step [5200/10000], Loss: 0.1820, Acc: 0.9375\n",
      "Step [5300/10000], Loss: 0.4308, Acc: 0.8125\n",
      "Step [5400/10000], Loss: 0.3290, Acc: 0.8750\n",
      "Step [5500/10000], Loss: 0.3333, Acc: 0.8750\n",
      "Step [5600/10000], Loss: 0.1203, Acc: 1.0000\n",
      "Step [5700/10000], Loss: 0.3838, Acc: 0.8750\n",
      "Step [5800/10000], Loss: 0.1335, Acc: 0.9375\n",
      "Step [5900/10000], Loss: 0.1209, Acc: 0.9375\n",
      "Step [6000/10000], Loss: 0.1818, Acc: 0.9375\n",
      "Step [6100/10000], Loss: 0.1939, Acc: 0.9375\n",
      "Step [6200/10000], Loss: 0.0436, Acc: 1.0000\n",
      "Step [6300/10000], Loss: 0.2287, Acc: 0.9375\n",
      "Step [6400/10000], Loss: 0.4919, Acc: 0.6875\n",
      "Step [6500/10000], Loss: 0.2550, Acc: 0.8125\n",
      "Step [6600/10000], Loss: 0.2561, Acc: 0.9375\n",
      "Step [6700/10000], Loss: 0.2470, Acc: 0.9375\n",
      "Step [6800/10000], Loss: 0.4218, Acc: 0.7500\n",
      "Step [6900/10000], Loss: 0.2479, Acc: 0.8750\n",
      "Step [7000/10000], Loss: 0.2280, Acc: 0.8125\n",
      "Step [7100/10000], Loss: 0.0712, Acc: 0.9375\n",
      "Step [7200/10000], Loss: 0.0448, Acc: 1.0000\n",
      "Step [7300/10000], Loss: 0.1818, Acc: 0.9375\n",
      "Step [7400/10000], Loss: 0.1785, Acc: 0.9375\n",
      "Step [7500/10000], Loss: 0.1110, Acc: 0.9375\n",
      "Step [7600/10000], Loss: 0.2204, Acc: 0.8750\n",
      "Step [7700/10000], Loss: 0.4184, Acc: 0.6875\n",
      "Step [7800/10000], Loss: 0.0854, Acc: 1.0000\n",
      "Step [7900/10000], Loss: 0.2027, Acc: 0.8125\n",
      "Step [8000/10000], Loss: 0.4113, Acc: 0.8125\n",
      "Step [8100/10000], Loss: 0.2568, Acc: 0.8750\n",
      "Step [8200/10000], Loss: 0.1454, Acc: 0.9375\n",
      "Step [8300/10000], Loss: 0.2129, Acc: 0.9375\n",
      "Step [8400/10000], Loss: 0.2811, Acc: 0.8750\n",
      "Step [8500/10000], Loss: 0.1423, Acc: 0.9375\n",
      "Step [8600/10000], Loss: 0.1193, Acc: 0.9375\n",
      "Step [8700/10000], Loss: 0.3033, Acc: 0.8750\n",
      "Step [8800/10000], Loss: 0.1677, Acc: 0.8750\n",
      "Step [8900/10000], Loss: 0.3718, Acc: 0.9375\n",
      "Step [9000/10000], Loss: 0.3337, Acc: 0.7500\n",
      "Step [9100/10000], Loss: 0.1981, Acc: 0.9375\n",
      "Step [9200/10000], Loss: 0.1235, Acc: 1.0000\n",
      "Step [9300/10000], Loss: 0.3392, Acc: 0.9375\n",
      "Step [9400/10000], Loss: 0.3104, Acc: 0.9375\n",
      "Step [9500/10000], Loss: 0.2515, Acc: 0.8125\n",
      "Step [9600/10000], Loss: 0.2816, Acc: 0.8750\n",
      "Step [9700/10000], Loss: 0.2797, Acc: 0.9375\n",
      "Step [9800/10000], Loss: 0.1807, Acc: 0.8750\n",
      "Step [9900/10000], Loss: 0.2253, Acc: 0.9375\n",
      "Step [10000/10000], Loss: 0.0929, Acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "for step in range(total_step):\n",
    "    if (step+1)%iter_per_epoch:\n",
    "        data_iter = iter(dataloader)\n",
    "    images, labels = next(data_iter)\n",
    "    images, labels = Variable(images).cuda(), Variable(labels).cuda()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = net2(images)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    _, argmax = torch.max(outputs, 1)\n",
    "    accuracy = (labels == argmax.squeeze()).float().mean()\n",
    "    if (step+1) % 100 == 0:\n",
    "        print ('Step [%d/%d], Loss: %.4f, Acc: %.4f' \n",
    "               %(step+1, total_step, loss.data[0], accuracy.data[0]))\n",
    "\n",
    "        #============ TensorBoard logging ============#\n",
    "        # (1) Log the scalar values\n",
    "        info = {\n",
    "            'loss': loss.data[0],\n",
    "            'accuracy': accuracy.data[0]\n",
    "        }\n",
    "\n",
    "        for tag, value in info.items():\n",
    "            logger.scalar_summary(tag, value, step+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the train images: 89 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in dataloader:\n",
    "    images = Variable(images.cuda())\n",
    "#     net2.eval()\n",
    "    outputs = net2(images)\n",
    "#     print(outputs.data)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "#     print(predicted)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted.cpu() == labels).sum()\n",
    "    \n",
    "print('Accuracy of the network on the train images: %d %%' % (100*correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(net2.state_dict(),'model_vgg_bn3.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
